{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet-pytorch in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.7.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\lib\\site-packages (from efficientnet-pytorch) (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch->efficientnet-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->efficientnet-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "class RoadSignDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory containing the images.\n",
    "            annotation_file (str): Path to the annotation file (gt.txt).\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_file = annotation_file\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load the annotations from the gt.txt file\n",
    "        self.annotations = self.load_annotations()\n",
    "    \n",
    "    def load_annotations(self):\n",
    "        \"\"\"\n",
    "        Load the annotations from the `gt.txt` file.\n",
    "        Assumes the format: image_name;xmin;ymin;xmax;ymax;class_label\n",
    "        \"\"\"\n",
    "        annotations = pd.read_csv(self.annotation_file, header=None, delimiter=';',\n",
    "                                names=['image_name', 'xmin', 'ymin', 'xmax', 'ymax', 'class_label'])\n",
    "        return annotations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the annotation for this index\n",
    "        annotation = self.annotations.iloc[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image_path = os.path.join(self.image_dir, annotation['image_name'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Open image as RGB\n",
    "        \n",
    "        # Get the bounding box coordinates and label\n",
    "        boxes = torch.tensor([[\n",
    "            float(annotation['xmin']),\n",
    "            float(annotation['ymin']),\n",
    "            float(annotation['xmax']),\n",
    "            float(annotation['ymax'])\n",
    "        ]], dtype=torch.float32)\n",
    "        \n",
    "        # Calculate area\n",
    "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        \n",
    "        # Prepare the target dictionary\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': torch.tensor([int(annotation['class_label'])], dtype=torch.int64),\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': area,\n",
    "            'iscrowd': torch.tensor([0], dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for the DataLoader to properly batch the images and targets\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    for img, tgt in batch:\n",
    "        images.append(img)\n",
    "        targets.append(tgt)\n",
    "    return images, targets\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = RoadSignDataset(\n",
    "    image_dir='D:/Work/DL/A3/ppm_images/train/images',\n",
    "    annotation_file='D:/Work/DL/A3/ppm_images/train/gt_train.txt',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = RoadSignDataset(\n",
    "    image_dir='D:/Work/DL/A3/ppm_images/validate/images',\n",
    "    annotation_file='D:/Work/DL/A3/ppm_images/validate/gt_validate.txt',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create DataLoaders with the custom collate_fn\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn  # Add this line\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn  # Add this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_8880\\983261059.py:82: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "\n",
    "class MobileNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Load pretrained MobileNetV3 Small (much lighter than EfficientNet)\n",
    "        mobile_net = mobilenet_v3_small(pretrained=pretrained)\n",
    "        \n",
    "        # Use features up to the last layer\n",
    "        self.features = mobile_net.features\n",
    "        \n",
    "        # MobileNetV3 Small output channels\n",
    "        self.out_channels = 576\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return OrderedDict([('0', x)])\n",
    "\n",
    "def create_model(num_classes, pretrained=True):\n",
    "    # Create backbone\n",
    "    backbone = MobileNetBackbone(pretrained=pretrained)\n",
    "    \n",
    "    # Create anchor generator with reduced anchors\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((32, 64, 128),),  # Reduced number of anchor sizes\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    from torchvision.ops import MultiScaleRoIAlign\n",
    "    roi_pooler = MultiScaleRoIAlign(\n",
    "        featmap_names=['0'],\n",
    "        output_size=5,  \n",
    "        sampling_ratio=2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model = FasterRCNN(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler,\n",
    "        \n",
    "        min_size=300,  \n",
    "        max_size=500,\n",
    "        rpn_pre_nms_top_n_train=500,   \n",
    "        rpn_pre_nms_top_n_test=250,    \n",
    "        rpn_post_nms_top_n_train=250,  \n",
    "        rpn_post_nms_top_n_test=125,   \n",
    "        rpn_batch_size_per_image=64,   \n",
    "        batch_size_per_image=32,       \n",
    "        rpn_score_thresh=0.05\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Memory optimization helper\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Create transforms with smaller image size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # Smaller size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 44  # Adjust based on your dataset\n",
    "model = create_model(num_classes=num_classes, pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "# Enable mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Use a memory-efficient optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# Update DataLoader with smaller batch size\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,  # Can try larger batch size due to smaller model\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, scaler):\n",
    "    \"\"\"\n",
    "    Train model for one epoch with mixed precision.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        optimizer: The optimizer\n",
    "        data_loader: DataLoader for training data\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        epoch: Current epoch number\n",
    "        scaler: GradScaler for mixed precision training\n",
    "    \n",
    "    Returns:\n",
    "        float: Average loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    for i, (images, targets) in enumerate(data_loader):\n",
    "       \n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        \n",
    "        total_loss += losses.item()\n",
    "        \n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            avg_loss = total_loss / (i + 1)\n",
    "            print(f\"Iteration: {i}, Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "       \n",
    "        del images, targets, losses, loss_dict\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch} finished. Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Iteration: 0, Average Loss: 31.9767\n",
      "Iteration: 10, Average Loss: 26.8436\n",
      "Iteration: 20, Average Loss: 26.5034\n",
      "Iteration: 30, Average Loss: 24.9370\n",
      "Iteration: 40, Average Loss: 23.7827\n",
      "Iteration: 50, Average Loss: 22.7474\n",
      "Iteration: 60, Average Loss: 21.7532\n",
      "Iteration: 70, Average Loss: 21.1665\n",
      "Iteration: 80, Average Loss: 20.5426\n",
      "Iteration: 90, Average Loss: 19.8081\n",
      "Iteration: 100, Average Loss: 19.3473\n",
      "Iteration: 110, Average Loss: 18.8817\n",
      "Iteration: 120, Average Loss: 18.4342\n",
      "Iteration: 130, Average Loss: 18.2189\n",
      "Iteration: 140, Average Loss: 17.9442\n",
      "Iteration: 150, Average Loss: 17.7413\n",
      "Iteration: 160, Average Loss: 17.4693\n",
      "Iteration: 170, Average Loss: 17.2666\n",
      "Epoch 1 finished. Average Loss: 17.2666\n",
      "Epoch 2\n",
      "Iteration: 0, Average Loss: 9.6163\n",
      "Iteration: 10, Average Loss: 13.2426\n",
      "Iteration: 20, Average Loss: 13.3852\n",
      "Iteration: 30, Average Loss: 13.2017\n",
      "Iteration: 40, Average Loss: 13.1833\n",
      "Iteration: 50, Average Loss: 13.3159\n",
      "Iteration: 60, Average Loss: 13.3343\n",
      "Iteration: 70, Average Loss: 13.2171\n",
      "Iteration: 80, Average Loss: 13.2554\n",
      "Iteration: 90, Average Loss: 13.3155\n",
      "Iteration: 100, Average Loss: 13.3637\n",
      "Iteration: 110, Average Loss: 13.3300\n",
      "Iteration: 120, Average Loss: 13.2880\n",
      "Iteration: 130, Average Loss: 13.1230\n",
      "Iteration: 140, Average Loss: 13.0390\n",
      "Iteration: 150, Average Loss: 13.0594\n",
      "Iteration: 160, Average Loss: 12.9624\n",
      "Iteration: 170, Average Loss: 12.9532\n",
      "Epoch 2 finished. Average Loss: 12.9532\n",
      "Epoch 3\n",
      "Iteration: 0, Average Loss: 13.6874\n",
      "Iteration: 10, Average Loss: 13.2521\n",
      "Iteration: 20, Average Loss: 12.2598\n",
      "Iteration: 30, Average Loss: 12.2290\n",
      "Iteration: 40, Average Loss: 11.9485\n",
      "Iteration: 50, Average Loss: 12.0644\n",
      "Iteration: 60, Average Loss: 12.4155\n",
      "Iteration: 70, Average Loss: 12.4792\n",
      "Iteration: 80, Average Loss: 12.3970\n",
      "Iteration: 90, Average Loss: 12.4856\n",
      "Iteration: 100, Average Loss: 12.4012\n",
      "Iteration: 110, Average Loss: 12.3136\n",
      "Iteration: 120, Average Loss: 12.3145\n",
      "Iteration: 130, Average Loss: 12.2066\n",
      "Iteration: 140, Average Loss: 12.2655\n",
      "Iteration: 150, Average Loss: 12.2636\n",
      "Iteration: 160, Average Loss: 12.3085\n",
      "Iteration: 170, Average Loss: 12.3809\n",
      "Epoch 3 finished. Average Loss: 12.3809\n",
      "Epoch 4\n",
      "Iteration: 0, Average Loss: 15.5827\n",
      "Iteration: 10, Average Loss: 12.8902\n",
      "Iteration: 20, Average Loss: 12.9565\n",
      "Iteration: 30, Average Loss: 12.9550\n",
      "Iteration: 40, Average Loss: 12.6797\n",
      "Iteration: 50, Average Loss: 12.6850\n",
      "Iteration: 60, Average Loss: 12.4259\n",
      "Iteration: 70, Average Loss: 12.2039\n",
      "Iteration: 80, Average Loss: 12.1129\n",
      "Iteration: 90, Average Loss: 12.0454\n",
      "Iteration: 100, Average Loss: 12.0631\n",
      "Iteration: 110, Average Loss: 12.1939\n",
      "Iteration: 120, Average Loss: 12.2018\n",
      "Iteration: 130, Average Loss: 12.0741\n",
      "Iteration: 140, Average Loss: 12.0520\n",
      "Iteration: 150, Average Loss: 12.1366\n",
      "Iteration: 160, Average Loss: 12.1311\n",
      "Iteration: 170, Average Loss: 12.1330\n",
      "Epoch 4 finished. Average Loss: 12.1330\n",
      "Epoch 5\n",
      "Iteration: 0, Average Loss: 15.7372\n",
      "Iteration: 10, Average Loss: 11.6566\n",
      "Iteration: 20, Average Loss: 12.2177\n",
      "Iteration: 30, Average Loss: 12.1459\n",
      "Iteration: 40, Average Loss: 11.8438\n",
      "Iteration: 50, Average Loss: 11.7672\n",
      "Iteration: 60, Average Loss: 11.6853\n",
      "Iteration: 70, Average Loss: 11.8950\n",
      "Iteration: 80, Average Loss: 12.0081\n",
      "Iteration: 90, Average Loss: 12.0405\n",
      "Iteration: 100, Average Loss: 11.9842\n",
      "Iteration: 110, Average Loss: 12.1068\n",
      "Iteration: 120, Average Loss: 12.0332\n",
      "Iteration: 130, Average Loss: 11.9972\n",
      "Iteration: 140, Average Loss: 12.0143\n",
      "Iteration: 150, Average Loss: 11.9932\n",
      "Iteration: 160, Average Loss: 12.0494\n",
      "Iteration: 170, Average Loss: 11.9644\n",
      "Epoch 5 finished. Average Loss: 11.9644\n",
      "Epoch 6\n",
      "Iteration: 0, Average Loss: 11.0064\n",
      "Iteration: 10, Average Loss: 11.9890\n",
      "Iteration: 20, Average Loss: 12.2528\n",
      "Iteration: 30, Average Loss: 11.9527\n",
      "Iteration: 40, Average Loss: 11.9741\n",
      "Iteration: 50, Average Loss: 11.9355\n",
      "Iteration: 60, Average Loss: 11.7271\n",
      "Iteration: 70, Average Loss: 11.6941\n",
      "Iteration: 80, Average Loss: 11.6760\n",
      "Iteration: 90, Average Loss: 11.6886\n",
      "Iteration: 100, Average Loss: 11.6209\n",
      "Iteration: 110, Average Loss: 11.7199\n",
      "Iteration: 120, Average Loss: 11.7928\n",
      "Iteration: 130, Average Loss: 11.7986\n",
      "Iteration: 140, Average Loss: 11.8193\n",
      "Iteration: 150, Average Loss: 11.8150\n",
      "Iteration: 160, Average Loss: 11.8179\n",
      "Iteration: 170, Average Loss: 11.8243\n",
      "Epoch 6 finished. Average Loss: 11.8243\n",
      "Epoch 7\n",
      "Iteration: 0, Average Loss: 8.6880\n",
      "Iteration: 10, Average Loss: 10.4534\n",
      "Iteration: 20, Average Loss: 11.1365\n",
      "Iteration: 30, Average Loss: 11.5433\n",
      "Iteration: 40, Average Loss: 11.4944\n",
      "Iteration: 50, Average Loss: 11.2627\n",
      "Iteration: 60, Average Loss: 11.2115\n",
      "Iteration: 70, Average Loss: 11.3722\n",
      "Iteration: 80, Average Loss: 11.5257\n",
      "Iteration: 90, Average Loss: 11.5731\n",
      "Iteration: 100, Average Loss: 11.6430\n",
      "Iteration: 110, Average Loss: 11.6145\n",
      "Iteration: 120, Average Loss: 11.6107\n",
      "Iteration: 130, Average Loss: 11.6418\n",
      "Iteration: 140, Average Loss: 11.6802\n",
      "Iteration: 150, Average Loss: 11.6611\n",
      "Iteration: 160, Average Loss: 11.7068\n",
      "Iteration: 170, Average Loss: 11.7517\n",
      "Epoch 7 finished. Average Loss: 11.7517\n",
      "Epoch 8\n",
      "Iteration: 0, Average Loss: 11.1615\n",
      "Iteration: 10, Average Loss: 11.9551\n",
      "Iteration: 20, Average Loss: 11.2936\n",
      "Iteration: 30, Average Loss: 11.2902\n",
      "Iteration: 40, Average Loss: 11.2665\n",
      "Iteration: 50, Average Loss: 11.4007\n",
      "Iteration: 60, Average Loss: 11.1289\n",
      "Iteration: 70, Average Loss: 11.4441\n",
      "Iteration: 80, Average Loss: 11.5642\n",
      "Iteration: 90, Average Loss: 11.6898\n",
      "Iteration: 100, Average Loss: 11.7801\n",
      "Iteration: 110, Average Loss: 11.7579\n",
      "Iteration: 120, Average Loss: 11.6390\n",
      "Iteration: 130, Average Loss: 11.6263\n",
      "Iteration: 140, Average Loss: 11.6559\n",
      "Iteration: 150, Average Loss: 11.6589\n",
      "Iteration: 160, Average Loss: 11.6999\n",
      "Iteration: 170, Average Loss: 11.7135\n",
      "Epoch 8 finished. Average Loss: 11.7135\n",
      "Epoch 9\n",
      "Iteration: 0, Average Loss: 12.7731\n",
      "Iteration: 10, Average Loss: 11.2400\n",
      "Iteration: 20, Average Loss: 11.1340\n",
      "Iteration: 30, Average Loss: 11.4973\n",
      "Iteration: 40, Average Loss: 11.2429\n",
      "Iteration: 50, Average Loss: 11.3794\n",
      "Iteration: 60, Average Loss: 11.3828\n",
      "Iteration: 70, Average Loss: 11.4313\n",
      "Iteration: 80, Average Loss: 11.4420\n",
      "Iteration: 90, Average Loss: 11.4458\n",
      "Iteration: 100, Average Loss: 11.4409\n",
      "Iteration: 110, Average Loss: 11.4206\n",
      "Iteration: 120, Average Loss: 11.3961\n",
      "Iteration: 130, Average Loss: 11.3746\n",
      "Iteration: 140, Average Loss: 11.3563\n",
      "Iteration: 150, Average Loss: 11.3700\n",
      "Iteration: 160, Average Loss: 11.4938\n",
      "Iteration: 170, Average Loss: 11.5564\n",
      "Epoch 9 finished. Average Loss: 11.5564\n",
      "Epoch 10\n",
      "Iteration: 0, Average Loss: 10.4756\n",
      "Iteration: 10, Average Loss: 11.4354\n",
      "Iteration: 20, Average Loss: 11.5782\n",
      "Iteration: 30, Average Loss: 11.6696\n",
      "Iteration: 40, Average Loss: 11.6967\n",
      "Iteration: 50, Average Loss: 11.3325\n",
      "Iteration: 60, Average Loss: 11.5039\n",
      "Iteration: 70, Average Loss: 11.4905\n",
      "Iteration: 80, Average Loss: 11.6366\n",
      "Iteration: 90, Average Loss: 11.5177\n",
      "Iteration: 100, Average Loss: 11.4931\n",
      "Iteration: 110, Average Loss: 11.5281\n",
      "Iteration: 120, Average Loss: 11.4960\n",
      "Iteration: 130, Average Loss: 11.4799\n",
      "Iteration: 140, Average Loss: 11.4678\n",
      "Iteration: 150, Average Loss: 11.5394\n",
      "Iteration: 160, Average Loss: 11.5190\n",
      "Iteration: 170, Average Loss: 11.4700\n",
      "Epoch 10 finished. Average Loss: 11.4700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = torch.amp.GradScaler()  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    avg_loss = train_one_epoch(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        device=device,\n",
    "        epoch=epoch,\n",
    "        scaler=scaler\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, 'model_full.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
